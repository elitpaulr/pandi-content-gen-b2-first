#!/usr/bin/env python3
"""
Test script for Ollama integration
Run this to verify that Ollama is working correctly with the project
"""

import sys
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

def test_ollama_connection():
    """Test basic Ollama connection"""
    print("ğŸ” Testing Ollama connection...")
    
    try:
        from llm.ollama_client import OllamaClient
        
        client = OllamaClient()
        
        if client.check_connection():
            print("âœ… Ollama connection successful!")
            
            models = client.list_models()
            print(f"ğŸ“‹ Available models: {models}")
            
            if models:
                print("ğŸ¯ Testing text generation...")
                response = client.generate_text(
                    "Write a short sentence about language learning.",
                    "You are a helpful assistant."
                )
                print(f"ğŸ’¬ Generated text: {response[:100]}...")
                print("âœ… Text generation working!")
                return True
            else:
                print("âš ï¸  No models found. Pull a model first: ollama pull llama3.1:8b")
                return False
                
        else:
            print("âŒ Failed to connect to Ollama")
            return False
            
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        print("Make sure to install requirements: pip install -r requirements.txt")
        return False
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

def test_task_generation():
    """Test Reading Part 5 task generation"""
    print("\nğŸ¯ Testing task generation...")
    
    try:
        from content.ollama_part5_generator import OllamaTaskGenerator
        
        generator = OllamaTaskGenerator()
        
        if not generator.check_ollama_status():
            print("âŒ Ollama not ready for task generation")
            return False
        
        print("ğŸš€ Generating a test task...")
        task = generator.generate_single_task("sustainable travel", 999)
        
        print("âœ… Task generation successful!")
        print(f"ğŸ“– Title: {task['title']}")
        print(f"ğŸ“ Text length: {len(task['text'].split())} words")
        print(f"â“ Questions: {len(task['questions'])}")
        print(f"ğŸ·ï¸  Category: {task.get('topic_category', 'unknown')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Task generation failed: {e}")
        return False

def main():
    """Run all tests"""
    print("ğŸ§ª Ollama Integration Test Suite")
    print("=" * 40)
    
    # Test 1: Basic connection
    connection_ok = test_ollama_connection()
    
    if not connection_ok:
        print("\nâŒ Basic connection failed. Please check:")
        print("1. Ollama is installed: https://ollama.ai/")
        print("2. Ollama is running: ollama serve")
        print("3. A model is available: ollama pull llama3.1:8b")
        return 1
    
    # Test 2: Task generation
    generation_ok = test_task_generation()
    
    print("\n" + "=" * 40)
    if connection_ok and generation_ok:
        print("ğŸ‰ All tests passed! Ollama integration is working correctly.")
        print("\nNext steps:")
        print("1. Run the Ollama generator: streamlit run app/ollama_generator.py --server.port 8507")
        print("2. Or use command line: python src/content/ollama_part5_generator.py")
        return 0
    else:
        print("âŒ Some tests failed. Check the errors above.")
        return 1

if __name__ == "__main__":
    exit(main()) 