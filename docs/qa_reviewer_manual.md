# QA Reviewer Manual
## B2 First Content Generation - Quality Assurance Guide

### üìã Table of Contents
1. [Overview](#overview)
2. [Getting Started](#getting-started)
3. [QA Review Interface](#qa-review-interface)
4. [Step-by-Step Review Process](#step-by-step-review-process)
5. [QA Status Management](#qa-status-management)
6. [Filtering and Finding Tasks](#filtering-and-finding-tasks)
7. [Review Criteria and Guidelines](#review-criteria-and-guidelines)
8. [Common Issues and Solutions](#common-issues-and-solutions)
9. [Best Practices](#best-practices)
10. [Troubleshooting](#troubleshooting)

---

## üìñ Overview

The QA Review system allows human reviewers to evaluate and annotate B2 First Reading Part 5 tasks generated by the AI system. Each task can be reviewed at multiple levels:

- **Overall Task** - General quality and appropriateness
- **Title** - Relevance and engagement
- **Reading Text** - Content quality, length, and B2 level appropriateness
- **Individual Questions** - Each of the 6 questions can be reviewed separately

### QA Status Options
- **‚è≥ Pending** - Not yet reviewed (default status)
- **‚úÖ Approved** - Meets quality standards
- **‚ùå Rejected** - Does not meet standards, needs revision

---

## üöÄ Getting Started

### Step 1: Access the Application
1. Open your web browser
2. Navigate to the Streamlit application URL (typically `http://localhost:8596`)
3. Wait for the application to load and connect to Ollama

### Step 2: Navigate to Task Library
1. Click on the **"üìö Task Library"** tab
2. You'll see a dashboard with task statistics and QA status overview

### Step 3: Select QA Review Mode
1. In the **"View Mode"** dropdown, select **"üîç QA Review"**
2. This enables the QA annotation interface for all tasks

---

## üîç QA Review Interface

### Main Components

#### 1. **Task Selection Area**
- **Content Type**: Choose between "üìÑ Individual Tasks" or "üì¶ Batch Collections"
- **Filters**: Topic, Text Type, QA Status, and Search
- **Task List**: Shows tasks with QA status emojis (‚úÖ‚è≥‚ùå)

#### 2. **QA Status Dashboard**
- **Total Tasks**: Number of available tasks
- **Filtered Results**: Tasks matching current filters
- **‚úÖ Approved**: Count of approved tasks
- **‚è≥ Pending**: Count of pending tasks  
- **‚ùå Rejected**: Count of rejected tasks

#### 3. **QA Annotation Interface**
- **Reviewer Information**: Enter your name
- **Overall Task Review**: Status and notes for the entire task
- **Title Review**: Specific feedback on the task title
- **Text Review**: Evaluation of the reading passage
- **Question Reviews**: Individual assessment of each question
- **Save Functionality**: Persist annotations to JSON files

---

## üìù Step-by-Step Review Process

### Phase 1: Initial Setup

#### Step 1: Filter Tasks for Review
1. Go to **Task Library** ‚Üí **QA Review Mode**
2. Set **QA Status Filter** to **"‚è≥ Pending"** to see unreviewed tasks
3. Optionally filter by **Topic** or **Text Type** to focus on specific content
4. Use **Sort by "QA Status"** to prioritize pending tasks

#### Step 2: Select a Task
1. Choose a task from the dropdown list
2. Tasks show QA status: `‚è≥ reading_part5_task_01 - Sustainable Travel...`
3. Click **"üìÑ View Task"** to display the task content

### Phase 2: Task Review

#### Step 3: Enter Reviewer Information
1. In the **QA Review** section, enter your name in **"Reviewer Name"**
2. This will be recorded with all your annotations

#### Step 4: Review Overall Task Quality
1. Read through the entire task first
2. Assess overall quality, appropriateness for B2 level, and exam format compliance
3. Select status: **Pending/Approved/Rejected**
4. Add notes explaining your decision:
   ```
   Example: "Well-structured task with appropriate B2 vocabulary. 
   Questions test different skills effectively. Minor formatting issue in Q3."
   ```

#### Step 5: Review the Title
1. Evaluate if the title is:
   - Engaging and relevant to the content
   - Appropriate length (not too long/short)
   - Clear and understandable
2. Select status and add specific notes:
   ```
   Example: "Title clearly reflects content and would engage B2 learners. 
   Good use of descriptive language."
   ```

#### Step 6: Review the Reading Text
1. Check the text for:
   - **Length**: Should be 550-750 words (displayed in task info)
   - **B2 Level**: Appropriate vocabulary and complexity
   - **Content Quality**: Engaging, authentic, well-structured
   - **Text Type**: Matches selected format (magazine article, blog post, etc.)
2. Select status and provide detailed feedback:
   ```
   Example: "Excellent B2-level text at 642 words. Natural flow, 
   appropriate vocabulary range. Good use of paragraphs and transitions."
   ```

#### Step 7: Review Individual Questions
For each of the 6 questions, evaluate:

1. **Question Clarity**: Is the question clear and unambiguous?
2. **Answer Options**: Are all 4 options plausible and well-written?
3. **Correct Answer**: Is there clearly one best answer?
4. **Question Type**: Does it test the intended skill (inference, vocabulary, etc.)?
5. **Text Reference**: Does the question relate to specific parts of the text?

**Example Question Review:**
```
Question 1 Status: Approved
Notes: "Clear inference question with good distractors. 
Answer A is clearly correct based on paragraph 2. 
All options are plausible and well-written."
```

### Phase 3: Save and Continue

#### Step 8: Save Annotations
1. Ensure all sections have been reviewed
2. Click **"üíæ Save QA Annotations"**
3. Confirm success message appears
4. Review the **QA Summary** showing your annotation counts

#### Step 9: Move to Next Task
1. Return to task selection
2. Choose another pending task
3. Repeat the review process

---

## üìä QA Status Management

### Understanding Status Hierarchy
The **Overall Task** status is the primary indicator used for:
- Task filtering and sorting
- Dashboard metrics
- Workflow prioritization

### Status Workflow
```
‚è≥ Pending (Default) ‚Üí Review Process ‚Üí ‚úÖ Approved OR ‚ùå Rejected
```

### Status Guidelines

#### ‚úÖ **Approved** - Use when:
- Task meets all B2 First exam standards
- Content is engaging and appropriate
- Questions are clear with one correct answer
- Minor issues that don't affect usability

#### ‚ùå **Rejected** - Use when:
- Significant content or format issues
- Questions are ambiguous or have multiple correct answers
- Text is inappropriate for B2 level
- Major structural problems

#### ‚è≥ **Pending** - Use when:
- Review is incomplete
- Waiting for second opinion
- Minor revisions needed before final decision

---

## üîç Filtering and Finding Tasks

### Quick Filters

#### By QA Status
- **"All Status"**: Show all tasks
- **"‚è≥ Pending"**: Focus on unreviewed tasks
- **"‚úÖ Approved"**: Review approved content
- **"‚ùå Rejected"**: Check rejected tasks for patterns

#### By Content Type
- **Topic Filter**: Focus on specific subject areas
- **Text Type Filter**: Review particular formats (articles, blogs, etc.)

#### By Priority
- **Sort by "QA Status"**: Approved ‚Üí Pending ‚Üí Rejected
- **Sort by "Recent First"**: Newest tasks first
- **Sort by "Task ID"**: Systematic review order

### Search Functionality
Use the search box to find tasks by:
- Title keywords
- Topic names
- Task IDs

### Batch Review
For **Batch Collections**:
1. Select **"üì¶ Batch Collections"**
2. View QA status summary for entire batches
3. Review individual tasks within batches
4. Track batch-level completion rates

---

## ‚úÖ Review Criteria and Guidelines

### B2 First Reading Part 5 Standards

#### Text Requirements
- **Length**: 550-750 words (flexible range 400-800)
- **Level**: Appropriate for B2 learners (intermediate-upper intermediate)
- **Content**: Engaging, authentic, well-structured
- **Topics**: Relevant to B2 age group and interests

#### Question Standards
- **Number**: Exactly 6 questions (numbered 1-6)
- **Format**: Multiple choice with 4 options (A, B, C, D)
- **Types**: Mix of inference, vocabulary, detail, attitude, reference, main idea
- **Clarity**: Unambiguous with one clearly correct answer
- **Difficulty**: Appropriate for B2 level

### Quality Indicators

#### ‚úÖ **Good Quality Markers**
- Natural, engaging writing style
- Appropriate vocabulary range for B2
- Clear paragraph structure
- Questions test different skills
- Realistic, plausible distractors
- Specific reference to text content

#### ‚ùå **Quality Issues**
- Artificial or stilted language
- Vocabulary too simple or too complex
- Unclear or ambiguous questions
- Multiple possible correct answers
- Generic questions not tied to text
- Poor grammar or spelling errors

### Common Question Types to Evaluate

1. **Inference Questions**: "What does the author suggest about...?"
2. **Vocabulary in Context**: "What does 'X' mean in line Y?"
3. **Detail Questions**: "According to the text, what happened when...?"
4. **Attitude/Opinion**: "How does the writer feel about...?"
5. **Reference Questions**: "What does 'it' refer to in paragraph 3?"
6. **Main Idea**: "What is the main purpose of this text?"

---

## ‚ö†Ô∏è Common Issues and Solutions

### Issue 1: Question Options Are Lists Instead of Dictionaries
**Symptom**: Error when viewing QA interface
**Solution**: This is automatically handled by the system - both formats are supported

### Issue 2: QA Annotations Not Saving
**Symptoms**: "No file path provided" message
**Solutions**:
1. Ensure you selected a task from the dropdown
2. Check that the task file exists and is accessible
3. Verify you have write permissions to the generated_tasks folder

### Issue 3: Tasks Not Showing QA Status
**Symptoms**: No emoji indicators in task lists
**Solutions**:
1. Refresh the page
2. Check that tasks have been loaded properly
3. Verify QA annotations structure in JSON files

### Issue 4: Filter Not Working
**Symptoms**: Filter selections don't change displayed tasks
**Solutions**:
1. Clear search box if it contains text
2. Reset filters to "All" options
3. Refresh the application

---

## üí° Best Practices

### Efficient Review Workflow

#### 1. **Batch Processing**
- Filter by status to focus on pending tasks
- Review similar content types together
- Use consistent evaluation criteria

#### 2. **Systematic Approach**
- Always read the entire task before making judgments
- Review in order: Overall ‚Üí Title ‚Üí Text ‚Üí Questions
- Take notes during review for consistent feedback

#### 3. **Quality Focus Areas**
- **Content Authenticity**: Does it sound natural?
- **B2 Appropriateness**: Right level of challenge?
- **Exam Compliance**: Follows Cambridge format?
- **Question Quality**: Clear, unambiguous, well-crafted?

### Documentation Standards

#### Effective Note-Taking
```
Good Example:
"Question 3: Approved - Clear vocabulary question testing 'sustainable' 
in context. All distractors plausible. Answer C clearly correct based 
on paragraph 2 usage."

Poor Example:
"OK"
```

#### Constructive Feedback
- Be specific about issues
- Suggest improvements when possible
- Note positive aspects as well as problems
- Reference specific parts of the text or questions

### Time Management
- **Quick Scan**: 2-3 minutes initial review
- **Detailed Review**: 10-15 minutes per task
- **Annotation**: 3-5 minutes for notes and status
- **Total**: 15-25 minutes per task

---

## üîß Troubleshooting

### Application Issues

#### Problem: Application Won't Load
**Solutions**:
1. Check that Ollama is running: `ollama serve`
2. Verify Streamlit is running on correct port
3. Clear browser cache and refresh

#### Problem: Tasks Not Displaying
**Solutions**:
1. Check `generated_tasks` folder exists and contains JSON files
2. Verify JSON files are valid format
3. Check file permissions

#### Problem: QA Interface Not Appearing
**Solutions**:
1. Ensure "üîç QA Review" is selected in View Mode
2. Refresh the page
3. Check browser console for JavaScript errors

### Data Issues

#### Problem: QA Status Not Updating
**Solutions**:
1. Verify reviewer name is entered
2. Check file write permissions
3. Ensure task file path is valid

#### Problem: Annotations Lost After Refresh
**Solutions**:
1. Always click "Save QA Annotations" before navigating away
2. Check that JSON files are being updated
3. Verify no file locking issues

### Performance Issues

#### Problem: Slow Loading
**Solutions**:
1. Reduce number of tasks in generated_tasks folder
2. Clear browser cache
3. Check system resources

---

## üìû Support and Resources

### Getting Help
- Check the troubleshooting section above
- Review error messages in the application
- Check browser developer console for technical errors

### Quality Standards Reference
- Cambridge B2 First official materials
- Sample tasks in the knowledge_base folder
- Approved tasks for comparison examples

### Feedback and Improvements
- Document recurring issues for system improvements
- Suggest new features for the QA interface
- Share best practices with other reviewers

---

## üìà Workflow Summary

### Daily Review Process
1. **Start**: Open application ‚Üí Task Library ‚Üí QA Review Mode
2. **Filter**: Set to "‚è≥ Pending" tasks
3. **Review**: Select task ‚Üí Complete all sections ‚Üí Save annotations
4. **Track**: Monitor dashboard metrics for progress
5. **Report**: Note any systemic issues or patterns

### Quality Metrics to Track
- **Approval Rate**: Percentage of tasks approved
- **Common Issues**: Recurring problems in generated content
- **Review Speed**: Tasks completed per hour
- **Consistency**: Similar evaluation standards across tasks

---

*This manual is designed to ensure consistent, high-quality review of AI-generated B2 First exam content. Regular updates will be made based on reviewer feedback and system improvements.* 